{
  "cli_patterns": "```json\n{\n  \"rosa_cli_commands\": {\n    \"account_management\": [\n      {\n        \"command\": \"rosa login\",\n        \"syntax\": \"rosa login [OPTIONS]\",\n        \"options\": [\n          \"--token TOKEN\",\n          \"--insecure\"\n        ],\n        \"description\": \"Log in to your Red Hat account\"\n      },\n      {\n        \"command\": \"rosa logout\",\n        \"syntax\": \"rosa logout\",\n        \"description\": \"Log out of your Red Hat account\"\n      }\n    ],\n    \"cluster_management\": [\n      {\n        \"command\": \"rosa create cluster\",\n        \"syntax\": \"rosa create cluster --cluster-name NAME [OPTIONS]\",\n        \"options\": [\n          \"--cluster-name NAME\",\n          \"--machine-cidr CIDR\",\n          \"--service-cidr CIDR\",\n          \"--host-prefix PREFIX\",\n          \"--multi-az|--single-az\",\n          \"--watch\",\n          \"--dry-run\"\n        ],\n        \"description\": \"Create a new OpenShift cluster on AWS\"\n      },\n      {\n        \"command\": \"rosa list clusters\",\n        \"syntax\": \"rosa list clusters\",\n        \"description\": \"List all OpenShift clusters\"\n      },\n      {\n        \"command\": \"rosa describe cluster\",\n        \"syntax\": \"rosa describe cluster --cluster CLUSTER\",\n        \"options\": [\n          \"--cluster CLUSTER\"\n        ],\n        \"description\": \"Describe a specific OpenShift cluster\"\n      },\n      {\n        \"command\": \"rosa delete cluster\",\n        \"syntax\": \"rosa delete cluster --cluster CLUSTER\",\n        \"options\": [\n          \"--cluster CLUSTER\",\n          \"--watch\",\n          \"--force\"\n        ],\n        \"description\": \"Delete an OpenShift cluster\"\n      }\n    ],\n    \"cluster_operations\": [\n      {\n        \"command\": \"rosa restart cluster\",\n        \"syntax\": \"rosa restart cluster --cluster CLUSTER\",\n        \"options\": [\n          \"--cluster CLUSTER\",\n          \"--watch\"\n        ],\n        \"description\": \"Restart an OpenShift cluster\"\n      },\n      {\n        \"command\": \"rosa upgrade cluster\",\n        \"syntax\": \"rosa upgrade cluster --cluster CLUSTER [OPTIONS]\",\n        \"options\": [\n          \"--cluster CLUSTER\",\n          \"--version VERSION\",\n          \"--watch\"\n        ],\n        \"description\": \"Upgrade an OpenShift cluster to a newer version\"\n      }\n    ]\n  },\n  \"common_command_patterns\": [\n    \"Most commands require the --cluster option to specify the target cluster\",\n    \"Many commands have a --watch option to stream progress updates\",\n    \"Dry-run options like --dry-run are available for preview operations\",\n    \"Cluster creation and deletion are separate commands\"\n  ],\n  \"best_practices\": [\n    \"Always authenticate with 'rosa login' before running other commands\",\n    \"Use descriptive cluster names for better organization\",\n    \"Plan network configurations (CIDR ranges, host prefixes) carefully\",\n    \"Consider multi-AZ deployments for high availability\",\n    \"Regularly check for and apply OpenShift upgrades\",\n    \"Back up cluster data before performing major operations\",\n    \"Use dry-run options to validate changes before applying them\"\n  ],\n  \"advanced_features_and_tips\": [\n    \"The rosa CLI supports bash auto-completion for easier command usage\",\n    \"Use the --output option to change the output format (e.g., JSON, YAML)\",\n    \"Leverage the --loglevel option for more detailed logging output\",\n    \"Integrate the rosa CLI with other AWS tools (e.g., AWS CLI, Terraform) for advanced use cases\",\n    \"Explore the rosa CLI source code for deeper understanding and customization\"\n  ]\n}\n```",
  "networking": "```json\n{\n  \"Networking Configuration Best Practices\": [\n    \"Use private subnets for worker nodes and internal load balancers\",\n    \"Configure network policies to restrict pod-to-pod communication\",\n    \"Implement network encryption (IPsec or WireGuard) for cluster networking\",\n    \"Use separate VPCs or subnets for production and non-production clusters\",\n    \"Leverage AWS PrivateLink for secure communication with AWS services\"\n  ],\n  \"Private Cluster Setup Patterns\": [\n    \"Deploy the cluster in a private VPC with no internet gateway\",\n    \"Use AWS VPN or AWS Direct Connect for administrative access\",\n    \"Configure bastion hosts or AWS Systems Manager for secure access\",\n    \"Implement egress proxies or NAT gateways for controlled internet access\",\n    \"Leverage AWS PrivateLink for secure communication with AWS services\"\n  ],\n  \"Ingress Controller Configurations\": [\n    \"Use the ROSA-managed AWS Load Balancer Controller for ingress\",\n    \"Configure SSL/TLS termination at the load balancer level\",\n    \"Implement path-based routing for multiple applications\",\n    \"Enable AWS WAF for web application firewall protection\",\n    \"Leverage AWS Global Accelerator for global load balancing\"\n  ],\n  \"Load Balancer Recommendations\": [\n    \"Use AWS Network Load Balancers for high performance and low latency\",\n    \"Configure cross-zone load balancing for high availability\",\n    \"Implement health checks and target group configurations\",\n    \"Enable access logging and monitoring for load balancers\",\n    \"Leverage AWS Global Accelerator for global load balancing\"\n  ],\n  \"Security Group and Firewall Rules\": [\n    \"Restrict inbound traffic to control plane and worker nodes\",\n    \"Allow only necessary ports and protocols for cluster communication\",\n    \"Implement security group rules based on least privilege principle\",\n    \"Use AWS Network Firewall for distributed firewall protection\",\n    \"Leverage AWS Security Hub for continuous security monitoring\"\n  ]\n}\n```",
  "authentication": "```json\n{\n  \"identityProviderConfigurations\": [\n    {\n      \"type\": \"OpenID Connect\",\n      \"example\": {\n        \"identityProviders\": [\n          {\n            \"name\": \"my_idp_provider\",\n            \"mappingMethod\": \"claim\",\n            \"type\": \"OpenIDIdentityProvider\",\n            \"openID\": {\n              \"clientID\": \"my-client-id\",\n              \"clientSecret\": {\n                \"name\": \"my-client-secret\"\n              },\n              \"issuer\": \"https://my-idp-issuer.com\"\n            },\n            \"claims\": {\n              \"preferredUsername\": [\n                \"preferred_username\"\n              ],\n              \"name\": [\n                \"name\"\n              ],\n              \"email\": [\n                \"email\"\n              ]\n            }\n          }\n        ]\n      }\n    },\n    {\n      \"type\": \"LDAP\",\n      \"example\": {\n        \"identityProviders\": [\n          {\n            \"name\": \"my_ldap_provider\",\n            \"mappingMethod\": \"claim\",\n            \"type\": \"LDAPIdentityProvider\",\n            \"ldap\": {\n              \"attributes\": {\n                \"id\": [\n                  \"dn\"\n                ],\n                \"preferredUsername\": [\n                  \"uid\"\n                ],\n                \"name\": [\n                  \"cn\"\n                ],\n                \"email\": [\n                  \"mail\"\n                ]\n              },\n              \"bindDN\": \"uid=admin,cn=users,cn=accounts,dc=example,dc=com\",\n              \"bindPassword\": {\n                \"name\": \"ldap-secret\"\n              },\n              \"insecure\": false,\n              \"url\": \"ldap://ldap.example.com/ou=users,dc=example,dc=com?uid\"\n            }\n          }\n        ]\n      }\n    }\n  ],\n  \"iamRoleSetupPatterns\": [\n    {\n      \"name\": \"Dedicated Admin Role\",\n      \"description\": \"Create a dedicated IAM role with the required permissions for managing the ROSA cluster.\"\n    },\n    {\n      \"name\": \"Separate Roles for Different Personas\",\n      \"description\": \"Create separate IAM roles for different personas (e.g., developers, operators, auditors) with the least privileged access required for their respective responsibilities.\"\n    },\n    {\n      \"name\": \"Temporary Roles\",\n      \"description\": \"Use temporary IAM roles with short-lived credentials for specific tasks or automation scripts, and revoke the roles after use.\"\n    }\n  ],\n  \"rbacConfigurations\": [\n    {\n      \"name\": \"Principle of Least Privilege\",\n      \"description\": \"Assign the minimum required permissions to users, groups, and service accounts based on their roles and responsibilities.\"\n    },\n    {\n      \"name\": \"Role Separation\",\n      \"description\": \"Separate roles for different personas (e.g., developers, operators, auditors) and enforce role-based access control (RBAC) policies.\"\n    },\n    {\n      \"name\": \"Namespace Isolation\",\n      \"description\": \"Use namespaces to isolate resources and enforce RBAC policies at the namespace level.\"\n    },\n    {\n      \"name\": \"Audit Logging and Monitoring\",\n      \"description\": \"Enable audit logging and monitoring to track RBAC policy changes and user activities.\"\n    }\n  ],\n  \"securityBestPractices\": [\n    {\n      \"name\": \"Secure Communication\",\n      \"description\": \"Enable secure communication between components using TLS encryption and certificate management.\"\n    },\n    {\n      \"name\": \"Network Policies\",\n      \"description\": \"Implement network policies to control ingress and egress traffic between pods, namespaces, and external networks.\"\n    },\n    {\n      \"name\": \"Pod Security Policies\",\n      \"description\": \"Define and enforce pod security policies to restrict privileged container operations and resource usage.\"\n    },\n    {\n      \"name\": \"Vulnerability Management\",\n      \"description\": \"Regularly scan and update container images, operating systems, and dependencies to address known vulnerabilities.\"\n    },\n    {\n      \"name\": \"Backup and Disaster Recovery\",\n      \"description\": \"Implement backup and disaster recovery strategies for critical data and resources.\"\n    },\n    {\n      \"name\": \"Audit Logging and Monitoring\",\n      \"description\": \"Enable audit logging and monitoring to detect and respond to security incidents and policy violations.\"\n    }\n  ],\n  \"stsRecommendations\": [\n    {\n      \"name\": \"STS Mode for Production Environments\",\n      \"description\": \"Use STS (Secure Token Service) mode for production environments to enhance security and enable advanced features like RBAC and network policies.\"\n    },\n    {\n      \"name\": \"Separate STS Clusters\",\n      \"description\": \"Consider deploying separate STS clusters for different environments (e.g., development, staging, production) to isolate workloads and enforce different security policies.\"\n    },\n    {\n      \"name\": \"STS Cluster Backup and Recovery\",\n      \"description\": \"Implement backup and recovery strategies for STS clusters to ensure data integrity and business continuity.\"\n    },\n    {\n      \"name\": \"STS Cluster Monitoring and Logging\",\n      \"description\": \"Enable monitoring and logging for STS clusters to detect and respond to issues, security incidents, and policy violations.\"\n    }\n  ]\n}\n```",
  "operations": "```json\n{\n  \"clusterSizingRecommendations\": {\n    \"workerNodes\": {\n      \"minimumCount\": 3,\n      \"recommendedCount\": 6,\n      \"maxCount\": 100,\n      \"instanceTypes\": [\n        \"m5.xlarge\",\n        \"m5.2xlarge\",\n        \"m5.4xlarge\"\n      ],\n      \"storageCapacity\": \"100GB or more\"\n    },\n    \"controlPlane\": {\n      \"minimumCount\": 3,\n      \"recommendedCount\": 3,\n      \"instanceTypes\": [\n        \"m5.xlarge\",\n        \"m5.2xlarge\"\n      ]\n    }\n  },\n  \"machinePoolConfigurations\": {\n    \"workerPools\": [\n      {\n        \"name\": \"general-workers\",\n        \"instanceType\": \"m5.2xlarge\",\n        \"nodeCount\": 3,\n        \"autoScaling\": {\n          \"minNodes\": 3,\n          \"maxNodes\": 10\n        }\n      },\n      {\n        \"name\": \"compute-workers\",\n        \"instanceType\": \"m5.4xlarge\",\n        \"nodeCount\": 2,\n        \"autoScaling\": {\n          \"minNodes\": 2,\n          \"maxNodes\": 8\n        }\n      }\n    ]\n  },\n  \"autoScalingPatterns\": {\n    \"clusterAutoscaler\": {\n      \"enabled\": true,\n      \"bufferPercentage\": 10\n    },\n    \"machineAutoscaler\": {\n      \"enabled\": true,\n      \"scaleDownDelayAfterAdd\": \"10m\",\n      \"scaleDownDelayAfterDelete\": \"10m\"\n    },\n    \"horizontalPodAutoscaler\": {\n      \"enabled\": true,\n      \"metrics\": [\n        \"cpu\",\n        \"memory\"\n      ]\n    }\n  },\n  \"monitoringAndAlerting\": {\n    \"prometheusOperator\": {\n      \"enabled\": true,\n      \"retention\": \"15d\",\n      \"storageSize\": \"50Gi\"\n    },\n    \"alertmanager\": {\n      \"enabled\": true,\n      \"receivers\": [\n        \"slack\",\n        \"email\"\n      ]\n    }\n  },\n  \"troubleshootingGuides\": [\n    \"Review cluster operator status\",\n    \"Check node health and status\",\n    \"Inspect pod logs and events\",\n    \"Analyze metrics and alerts\",\n    \"Consult OpenShift documentation\"\n  ],\n  \"upgradeProcesses\": [\n    \"Backup etcd and persistent volumes\",\n    \"Upgrade control plane nodes\",\n    \"Upgrade worker nodes\",\n    \"Verify cluster health and functionality\",\n    \"Update monitoring and logging components\"\n  ]\n}\n```",
  "cost_optimization": "```json\n{\n  \"cost_optimization_strategies\": [\n    \"Utilize AWS Cost Explorer to monitor and analyze costs\",\n    \"Implement tagging strategies for better cost allocation and tracking\",\n    \"Leverage AWS Auto Scaling to automatically scale resources based on demand\",\n    \"Consider using AWS Reserved Instances for long-term workloads\",\n    \"Implement AWS Trusted Advisor recommendations for cost optimization\",\n    \"Regularly review and right-size resources based on utilization\"\n  ],\n  \"instance_type_recommendations\": [\n    \"For general-purpose workloads, consider using AWS EC2 instances from the M5 or M6g family\",\n    \"For compute-intensive workloads, consider using AWS EC2 instances from the C5 or C6g family\",\n    \"For memory-intensive workloads, consider using AWS EC2 instances from the R5 or R6g family\",\n    \"For GPU-accelerated workloads, consider using AWS EC2 instances from the P3 or G4 family\",\n    \"For ARM-based workloads, consider using AWS Graviton instances from the M6g or C6g family\"\n  ],\n  \"resource_sizing_guidelines\": [\n    \"Monitor resource utilization and scale resources based on actual demand\",\n    \"Use AWS Auto Scaling to automatically scale resources based on defined metrics\",\n    \"Consider using AWS CloudWatch to set alarms and notifications for resource utilization\",\n    \"Follow AWS best practices for sizing resources based on workload requirements\",\n    \"Regularly review and right-size resources based on utilization patterns\"\n  ],\n  \"reserved_instance_patterns\": [\n    \"Analyze historical usage patterns to identify long-term, predictable workloads\",\n    \"Consider using AWS Reserved Instances for long-term, predictable workloads\",\n    \"Utilize AWS Cost Explorer to identify potential savings with Reserved Instances\",\n    \"Implement a centralized Reserved Instance management strategy\",\n    \"Regularly review and modify Reserved Instance commitments based on changing workload patterns\"\n  ],\n  \"spot_instance_usage\": [\n    \"Identify workloads that can tolerate interruptions and are suitable for Spot Instances\",\n    \"Utilize AWS Auto Scaling to automatically scale Spot Instances based on demand\",\n    \"Implement fault-tolerant architectures to handle Spot Instance interruptions\",\n    \"Leverage AWS Spot Instance Advisor to identify potential savings with Spot Instances\",\n    \"Regularly monitor and adjust Spot Instance usage based on pricing and availability\"\n  ]\n}\n```",
  "integrations": "```json\n{\n  \"AWS_Service_Integration_Patterns\": [\n    {\n      \"Pattern\": \"AWS Load Balancer Integration\",\n      \"Description\": \"ROSA clusters can be integrated with AWS Elastic Load Balancing (ELB) services, such as Classic Load Balancer, Network Load Balancer, or Application Load Balancer, to distribute incoming traffic across multiple worker nodes.\"\n    },\n    {\n      \"Pattern\": \"AWS IAM Integration\",\n      \"Description\": \"ROSA can be configured to use AWS Identity and Access Management (IAM) for authentication and authorization, allowing for centralized user and access management.\"\n    },\n    {\n      \"Pattern\": \"AWS VPC Integration\",\n      \"Description\": \"ROSA clusters can be deployed within an existing AWS Virtual Private Cloud (VPC), enabling secure network communication and integration with other AWS services within the VPC.\"\n    }\n  ],\n  \"Storage_Integration\": [\n    {\n      \"Service\": \"AWS Elastic Block Store (EBS)\",\n      \"Description\": \"ROSA supports the use of AWS EBS volumes for persistent storage, providing high-performance block storage for applications running on OpenShift.\"\n    },\n    {\n      \"Service\": \"AWS Elastic File System (EFS)\",\n      \"Description\": \"ROSA can leverage AWS EFS for shared file storage, allowing multiple pods or nodes to access the same file system concurrently.\"\n    },\n    {\n      \"Service\": \"AWS Simple Storage Service (S3)\",\n      \"Description\": \"ROSA can integrate with AWS S3 for object storage, enabling applications to store and retrieve data from S3 buckets.\"\n    }\n  ],\n  \"Database_Connectivity_Patterns\": [\n    {\n      \"Pattern\": \"AWS RDS Integration\",\n      \"Description\": \"ROSA can connect to AWS Relational Database Service (RDS) for managed relational databases, such as MySQL, PostgreSQL, or Oracle.\"\n    },\n    {\n      \"Pattern\": \"AWS DynamoDB Integration\",\n      \"Description\": \"ROSA applications can interact with AWS DynamoDB, a fully managed NoSQL database service, for scalable and high-performance data storage.\"\n    },\n    {\n      \"Pattern\": \"AWS ElastiCache Integration\",\n      \"Description\": \"ROSA can leverage AWS ElastiCache, a fully managed in-memory data store, for caching and accelerating data access for applications.\"\n    }\n  ],\n  \"CI/CD_Pipeline_Examples\": [\n    {\n      \"Example\": \"OpenShift Pipelines\",\n      \"Description\": \"ROSA supports OpenShift Pipelines, a Kubernetes-native CI/CD solution based on Tekton, which allows for building, testing, and deploying applications using declarative pipelines.\"\n    },\n    {\n      \"Example\": \"AWS CodePipeline Integration\",\n      \"Description\": \"ROSA can integrate with AWS CodePipeline, a fully managed continuous delivery service, enabling automated release processes for applications deployed on ROSA clusters.\"\n    },\n    {\n      \"Example\": \"Jenkins on OpenShift\",\n      \"Description\": \"ROSA supports running Jenkins, a popular open-source automation server, on OpenShift for building and deploying applications using Jenkins pipelines.\"\n    }\n  ],\n  \"Observability_Stack_Setup\": [\n    {\n      \"Component\": \"Prometheus\",\n      \"Description\": \"ROSA includes Prometheus, a popular open-source monitoring and alerting system, for collecting and querying metrics from applications and cluster components.\"\n    },\n    {\n      \"Component\": \"Grafana\",\n      \"Description\": \"ROSA integrates with Grafana, a data visualization and analytics platform, allowing users to create dashboards and visualize metrics collected by Prometheus.\"\n    },\n    {\n      \"Component\": \"Elasticsearch, Fluentd, Kibana (EFK) Stack\",\n      \"Description\": \"ROSA supports the EFK stack, which includes Elasticsearch for log indexing, Fluentd for log collection and forwarding, and Kibana for log analysis and visualization.\"\n    }\n  ]\n}\n```",
  "enhancements": "```json\n{\n  \"tool_functions\": [\n    {\n      \"name\": \"validate_cluster_config\",\n      \"description\": \"Validate cluster configuration based on best practices\",\n      \"code\": \"def validate_cluster_config(config: dict) -> list:\\n    \\\"\\\"\\\"Validate cluster configuration against best practices.\\n\\n    Args:\\n        config (dict): Cluster configuration dictionary.\\n\\n    Returns:\\n        list: List of validation errors.\\n    \\\"\\\"\\\"\\n    errors = []\\n\\n    # Validate worker node count\\n    worker_count = config.get('worker_nodes', {}).get('nodeCount', 0)\\n    if worker_count < WORKER_NODE_MIN_COUNT:\\n        errors.append(f'Worker node count ({worker_count}) is below the recommended minimum ({WORKER_NODE_MIN_COUNT}).')\\n\\n    # Validate control plane node count\\n    control_plane_count = config.get('control_plane', {}).get('nodeCount', 0)\\n    if control_plane_count < CONTROL_PLANE_MIN_COUNT:\\n        errors.append(f'Control plane node count ({control_plane_count}) is below the recommended minimum ({CONTROL_PLANE_MIN_COUNT}).')\\n\\n    # Add more validation rules as needed\\n\\n    return errors\"\n    },\n    {\n      \"name\": \"apply_dry_run\",\n      \"description\": \"Perform a dry-run operation before applying changes\",\n      \"code\": \"def apply_dry_run(operation: Callable, *args, **kwargs) -> None:\\n    \\\"\\\"\\\"Perform a dry-run operation before applying changes.\\n\\n    Args:\\n        operation (Callable): The operation to be performed.\\n        *args: Positional arguments for the operation.\\n        **kwargs: Keyword arguments for the operation.\\n    \\\"\\\"\\\"\\n    print('Performing dry-run...')\\n    operation(*args, dry_run=True, **kwargs)\\n    print('Dry-run completed successfully. Review the changes and proceed with caution.')\"\n    }\n  ],\n  \"function_enhancements\": [\n    {\n      \"name\": \"create_cluster\",\n      \"enhancement\": \"Add validation for cluster configuration and network settings\"\n    },\n    {\n      \"name\": \"upgrade_cluster\",\n      \"enhancement\": \"Implement backup and recovery strategies before upgrading\"\n    },\n    {\n      \"name\": \"delete_cluster\",\n      \"enhancement\": \"Add dry-run option and confirmation prompt\"\n    }\n  ],\n  \"validation_rules\": [\n    {\n      \"name\": \"validate_network_config\",\n      \"description\": \"Validate network configuration based on recommendations\",\n      \"code\": \"def validate_network_config(config: dict) -> list:\\n    \\\"\\\"\\\"Validate network configuration against recommendations.\\n\\n    Args:\\n        config (dict): Network configuration dictionary.\\n\\n    Returns:\\n        list: List of validation errors.\\n    \\\"\\\"\\\"\\n    errors = []\\n\\n    # Validate CIDR ranges\\n    machine_cidr = config.get('machine_cidr')\\n    service_cidr = config.get('service_cidr')\\n    if not is_valid_cidr(machine_cidr):\\n        errors.append(f'Invalid machine CIDR range: {machine_cidr}')\\n    if not is_valid_cidr(service_cidr):\\n        errors.append(f'Invalid service CIDR range: {service_cidr}')\\n\\n    # Validate host prefix\\n    host_prefix = config.get('host_prefix')\\n    if not (1 <= host_prefix <= 32):\\n        errors.append(f'Invalid host prefix: {host_prefix}. Must be between 1 and 32.')\\n\\n    # Add more validation rules as needed\\n\\n    return errors\"\n    }\n  ],\n  \"helper_functions\": [\n    {\n      \"name\": \"perform_cluster_upgrade\",\n      \"description\": \"Helper function to perform a cluster upgrade\",\n      \"code\": \"def perform_cluster_upgrade(cluster_name: str, target_version: str) -> None:\\n    \\\"\\\"\\\"Perform a cluster upgrade to the specified target version.\\n\\n    Args:\\n        cluster_name (str): Name of the cluster to upgrade.\\n        target_version (str): Target OpenShift version for the upgrade.\\n    \\\"\\\"\\\"\\n    cluster = get_cluster(cluster_name)\\n    current_version = cluster.version\\n\\n    if current_version == target_version:\\n        print(f'Cluster {cluster_name} is already at version {target_version}.')\\n        return\\n\\n    print(f'Backing up cluster {cluster_name} before upgrade...')\\n    backup_cluster(cluster_name)\\n\\n    print(f'Upgrading cluster {cluster_name} from {current_version} to {target_version}...')\\n    upgrade_cluster(cluster_name, target_version)\\n\\n    print(f'Upgrade completed. Verifying cluster health...')\\n    verify_cluster_health(cluster_name)\\n\\n    print(f'Upgrading monitoring and logging components...')\\n    upgrade_monitoring_components(cluster_name)\\n\\n    print(f'Cluster {cluster_name} has been successfully upgraded to version {target_version}.')\"\n    }\n  ],\n  \"constants\": [\n    {\n      \"name\": \"WORKER_NODE_MIN_COUNT\",\n      \"value\": 3,\n      \"description\": \"Minimum recommended number of worker nodes\"\n    },\n    {\n      \"name\": \"WORKER_NODE_RECOMMENDED_COUNT\",\n      \"value\": 6,\n      \"description\": \"Recommended number of worker nodes\"\n    },\n    {\n      \"name\": \"CONTROL_PLANE_MIN_COUNT\",\n      \"value\": 3,\n      \"description\": \"Minimum recommended number of control plane nodes\"\n    },\n    {\n      \"name\": \"CONTROL_PLANE_RECOMMENDED_COUNT\",\n      \"value\": 3,\n      \"description\": \"Recommended number of control plane nodes\"\n    },\n    {\n      \"name\": \"RECOMMENDED_INSTANCE_TYPES\",\n      \"value\": [\"m5.xlarge\", \"m5.2xlarge\", \"m5.4xlarge\"],\n      \"description\": \"Recommended instance types for worker nodes\"\n    }\n  ]\n}\n```"
}